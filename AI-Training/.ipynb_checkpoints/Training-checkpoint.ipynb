{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Training\n",
    "## Edge model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp39-cp39-macosx_12_0_arm64.whl (239.4 MB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.13.0-cp39-cp39-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 709 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2.1.0,>=1.26.0\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl (3.5 MB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./training/lib/python3.9/site-packages (from tensorflow) (58.1.0)\n",
      "Collecting packaging\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Using cached ml_dtypes-0.4.1-cp39-cp39-macosx_10_9_universal2.whl (396 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.70.0-cp39-cp39-macosx_10_14_universal2.whl (11.5 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.14.1-cp39-cp39-macosx_11_0_arm64.whl (327 kB)\n",
      "\u001b[K     |████████████████████████████████| 327 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl (197 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: zipp, mdurl, typing-extensions, pygments, numpy, MarkupSafe, markdown-it-py, importlib-metadata, wheel, werkzeug, urllib3, tensorboard-data-server, six, rich, protobuf, packaging, optree, namex, ml-dtypes, markdown, idna, h5py, grpcio, charset-normalizer, certifi, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard, requests, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 idna-3.10 importlib-metadata-8.6.1 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.1 packaging-24.2 protobuf-5.29.3 pygments-2.19.1 requests-2.32.3 rich-13.9.4 six-1.17.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 typing-extensions-4.12.2 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2 zipp-3.21.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/benshorten/Desktop/FYP/AI-Training/training/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tensorflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - control_output_loss: 0.5303 - control_output_mae: 0.2954 - edge_output_loss: 145.1925 - edge_output_mae: 3.4171 - loss: 145.7229 - val_control_output_loss: 0.0668 - val_control_output_mae: 0.2123 - val_edge_output_loss: 0.1433 - val_edge_output_mae: 0.3114 - val_loss: 0.2101\n",
      "Epoch 2/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - control_output_loss: 0.0536 - control_output_mae: 0.1401 - edge_output_loss: 0.1630 - edge_output_mae: 0.3001 - loss: 0.2166 - val_control_output_loss: 0.0508 - val_control_output_mae: 0.1058 - val_edge_output_loss: 0.5031 - val_edge_output_mae: 0.6292 - val_loss: 0.5539\n",
      "Epoch 3/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - control_output_loss: 0.0471 - control_output_mae: 0.1063 - edge_output_loss: 0.3022 - edge_output_mae: 0.3900 - loss: 0.3494 - val_control_output_loss: 0.0454 - val_control_output_mae: 0.0882 - val_edge_output_loss: 4.7316 - val_edge_output_mae: 2.0258 - val_loss: 4.7771\n",
      "Epoch 4/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - control_output_loss: 0.0451 - control_output_mae: 0.1005 - edge_output_loss: 0.6055 - edge_output_mae: 0.4435 - loss: 0.6506 - val_control_output_loss: 0.0426 - val_control_output_mae: 0.1212 - val_edge_output_loss: 0.0809 - val_edge_output_mae: 0.2297 - val_loss: 0.1235\n",
      "Epoch 5/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - control_output_loss: 0.0434 - control_output_mae: 0.0950 - edge_output_loss: 0.3012 - edge_output_mae: 0.3641 - loss: 0.3446 - val_control_output_loss: 0.0409 - val_control_output_mae: 0.0968 - val_edge_output_loss: 0.0910 - val_edge_output_mae: 0.2557 - val_loss: 0.1319\n",
      "Epoch 6/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - control_output_loss: 0.0427 - control_output_mae: 0.0925 - edge_output_loss: 0.1801 - edge_output_mae: 0.3213 - loss: 0.2228 - val_control_output_loss: 0.0386 - val_control_output_mae: 0.0811 - val_edge_output_loss: 0.1457 - val_edge_output_mae: 0.3281 - val_loss: 0.1843\n",
      "Epoch 7/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - control_output_loss: 0.0415 - control_output_mae: 0.0896 - edge_output_loss: 0.1324 - edge_output_mae: 0.2726 - loss: 0.1739 - val_control_output_loss: 0.0397 - val_control_output_mae: 0.0924 - val_edge_output_loss: 0.2144 - val_edge_output_mae: 0.3956 - val_loss: 0.2541\n",
      "Epoch 8/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - control_output_loss: 0.0418 - control_output_mae: 0.0888 - edge_output_loss: 0.1152 - edge_output_mae: 0.2588 - loss: 0.1570 - val_control_output_loss: 0.0395 - val_control_output_mae: 0.0917 - val_edge_output_loss: 0.0848 - val_edge_output_mae: 0.2144 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - control_output_loss: 0.0411 - control_output_mae: 0.0874 - edge_output_loss: 0.1063 - edge_output_mae: 0.2462 - loss: 0.1474 - val_control_output_loss: 0.0383 - val_control_output_mae: 0.0824 - val_edge_output_loss: 0.1142 - val_edge_output_mae: 0.2981 - val_loss: 0.1525\n",
      "Epoch 10/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - control_output_loss: 0.0404 - control_output_mae: 0.0849 - edge_output_loss: 0.0887 - edge_output_mae: 0.2214 - loss: 0.1291 - val_control_output_loss: 0.0401 - val_control_output_mae: 0.0937 - val_edge_output_loss: 0.0444 - val_edge_output_mae: 0.1151 - val_loss: 0.0845\n",
      "Epoch 1/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 717us/step - edge_output_mae: 0.1403 - loss: 0.0494 - val_edge_output_mae: 0.1371 - val_loss: 0.0481\n",
      "Epoch 2/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - edge_output_mae: 0.1385 - loss: 0.0484 - val_edge_output_mae: 0.1879 - val_loss: 0.0562\n",
      "Epoch 3/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - edge_output_mae: 0.1365 - loss: 0.0473 - val_edge_output_mae: 0.1137 - val_loss: 0.0425\n",
      "Epoch 4/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - edge_output_mae: 0.1371 - loss: 0.0480 - val_edge_output_mae: 0.1468 - val_loss: 0.0514\n",
      "Epoch 5/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650us/step - edge_output_mae: 0.1363 - loss: 0.0477 - val_edge_output_mae: 0.1387 - val_loss: 0.0461\n",
      "Epoch 6/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - edge_output_mae: 0.1366 - loss: 0.0476 - val_edge_output_mae: 0.1122 - val_loss: 0.0431\n",
      "Epoch 7/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - edge_output_mae: 0.1375 - loss: 0.0478 - val_edge_output_mae: 0.1394 - val_loss: 0.0454\n",
      "Epoch 8/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - edge_output_mae: 0.1374 - loss: 0.0480 - val_edge_output_mae: 0.1371 - val_loss: 0.0457\n",
      "Epoch 9/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 981us/step - edge_output_mae: 0.1389 - loss: 0.0486 - val_edge_output_mae: 0.1136 - val_loss: 0.0428\n",
      "Epoch 10/10\n",
      "\u001b[1m3184/3184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 866us/step - edge_output_mae: 0.1404 - loss: 0.0490 - val_edge_output_mae: 0.1601 - val_loss: 0.0509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ e1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ e2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ edge_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ e1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ e2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ edge_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,461</span> (13.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,461\u001b[0m (13.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (132.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33\u001b[0m (132.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,360</span> (13.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,360\u001b[0m (13.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> (276.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m68\u001b[0m (276.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ controlmodel (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ control_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ controlmodel (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ control_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,673</span> (330.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,673\u001b[0m (330.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,673</span> (330.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,673\u001b[0m (330.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess data\n",
    "RAIN_THRESHHOLD = 0.5\n",
    "data = pd.read_csv('weather_data.csv', low_memory=False)\n",
    "data = data.sample(frac=1, random_state=2).reset_index(drop=True)\n",
    "data = data.replace('', float('nan')).dropna()\n",
    "\n",
    "# Encode rain to 1 or 0 depending on threshold\n",
    "y = data['rain'].apply(lambda x: 1 if x > RAIN_THRESHHOLD else 0)\n",
    "X = data.drop(columns=['rain', 'date'])\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Ensure all data is numeric\n",
    "X = X.astype(float)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape y to (num_samples, 1) for regression\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = layers.Dense(64, activation='relu', name='e1')(inputs)\n",
    "x_edge = layers.Dense(32, activation='relu', name='e2')(x)\n",
    "edge_outputs = layers.Dense(1, activation='linear', name='edge_output')(x_edge)\n",
    "x = layers.Dense(64, activation='relu', name='controlmodel')(x_edge)\n",
    "x = layers.Dense(128, activation='relu', name='l1')(x)\n",
    "x = layers.Dense(256, activation='relu', name='l2')(x)\n",
    "x = layers.Dense(128, activation='relu', name='l3')(x)\n",
    "x = layers.Dense(64, activation='relu', name='l4')(x)\n",
    "control_outputs = layers.Dense(1, activation='linear', name='control_output')(x)\n",
    "\n",
    "# Create and compile the combined model\n",
    "combined_model = Model(inputs=inputs, outputs=[edge_outputs, control_outputs])\n",
    "combined_model.compile(optimizer='adam',\n",
    "                       loss={'edge_output': 'mean_squared_error',\n",
    "                             'control_output': 'mean_squared_error'},\n",
    "                       metrics={'edge_output': 'mae',\n",
    "                                'control_output': 'mae'})\n",
    "\n",
    "# Train the combined model\n",
    "combined_model.fit(X_train, [y_train, y_train], \n",
    "                   epochs=10, batch_size=32, \n",
    "                   validation_data=(X_test, [y_test, y_test]))\n",
    "\n",
    "# Define the edge_model\n",
    "edge_model = Model(inputs=inputs, outputs=[combined_model.get_layer('e2').output, edge_outputs])\n",
    "\n",
    "# x§This needs training \n",
    "# Set last as untrainable, then train last ones, this is not needed for contorl model becasue its last output is trained when entire model \n",
    "# gets trained\n",
    "for layer in edge_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "edge_model.get_layer('edge_output').trainable = True\n",
    "\n",
    "edge_model.compile(optimizer='adam',\n",
    "                   loss={'e2': None, 'edge_output': 'mean_squared_error'},  # Ignore loss for 'e2', we only care about the output of the inference\n",
    "                   metrics={'edge_output': 'mae'})\n",
    "\n",
    "edge_model.fit(X_train, [y_train, y_train], \n",
    "               epochs=10, batch_size=32, \n",
    "               validation_data=(X_test, [y_test, y_test]))\n",
    "\n",
    "# Define the control_model\n",
    "control_model_input = Input(shape=(32,))  # Shape of the intermediate layer output\n",
    "z = combined_model.get_layer('controlmodel')(control_model_input)\n",
    "z = combined_model.get_layer('l1')(z)\n",
    "z = combined_model.get_layer('l2')(z)\n",
    "z = combined_model.get_layer('l3')(z)\n",
    "z = combined_model.get_layer('l4')(z)\n",
    "control_model_outputs = combined_model.get_layer('control_output')(z)\n",
    "control_model = Model(inputs=control_model_input, outputs=control_model_outputs)\n",
    "\n",
    "# Inspect the models\n",
    "edge_model.summary()\n",
    "control_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - control_output_loss: 0.0468 - control_output_mae: 0.0913 - edge_output_loss: 0.0480 - edge_output_mae: 0.1352 - loss: 0.0948\n",
      "Test Loss: 0.09326030313968658\n",
      "Edge Output - MAE: 0.04743298888206482\n",
      "Edge Output - MSE - How much its off by on average: 0.04583030194044113\n",
      "Control Output - MAE: 0.09009821712970734\n",
      "Control Output - MSE: 0.13423798978328705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = combined_model.evaluate(X_test, [y_test, y_test])\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Edge Output - MAE:\", results[1])\n",
    "print(\"Edge Output - MSE - How much its off by on average:\", results[2])\n",
    "print(\"Control Output - MAE:\", results[3])\n",
    "print(\"Control Output - MSE:\", results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: expt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: expt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'expt'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 19), dtype=tf.float32, name='keras_tensor_54')\n",
      "Output Type:\n",
      "  List[TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  4531610320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4531613584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4531617424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4531613392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4531616272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4531615888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1741185165.733189   73505 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1741185165.735712   73505 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-03-05 14:32:45.738432: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./expt\n",
      "2025-03-05 14:32:45.738945: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-03-05 14:32:45.738952: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: ./expt\n",
      "2025-03-05 14:32:45.749383: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-03-05 14:32:45.825329: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: ./expt\n",
      "2025-03-05 14:32:45.830744: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 92315 microseconds.\n"
     ]
    }
   ],
   "source": [
    "edge_model.export(\"expt\")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('./expt')\n",
    "tflite_model = converter.convert()\n",
    "with open('../deployment/models/edge_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "edge_model.save('../deployment/models/edge_model.keras')\n",
    "    \n",
    "control_model.save('../deployment/models/control_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4QVah7jpikD"
   },
   "source": [
    "# On the AI Edge Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8KUIFLQqDdn",
    "outputId": "89dbe9c1-4d7b-4fd8-cdf3-d21cc5437056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0.      ,    0.      , 1736.833   ,    0.      ,    0.      ,\n",
       "        122.79834 ,    0.      ,    0.      ,    0.      ,  498.57092 ,\n",
       "        308.47418 ,    0.      ,    0.      ,    0.      , 2261.8982  ,\n",
       "       1048.9276  ,    0.      ,    0.      ,  886.5067  ,    0.      ,\n",
       "          0.      , 1980.9333  ,  846.6481  ,    0.      , 1223.5721  ,\n",
       "          0.      ,   91.276794, 1690.1853  , 1646.5259  ,  399.7732  ,\n",
       "          0.      ,  788.00134 ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_edge_litert.interpreter import Interpreter\n",
    "interpreter = Interpreter(model_path='../deployment/models/edge_model.tflite')\n",
    "signatures = interpreter.get_signature_list()\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# FEED IN THE INPUT DATA\n",
    "input_details = interpreter.get_input_details()\n",
    "input_data = np.array([[0,0,8.7,0,8.6,8.5,11.1,99,1003.1,2,12,2,350,61,66,0.0,15000,45,8]], dtype=np.float32)\n",
    "# Set input tensor\n",
    "input_index = input_details[0]['index']\n",
    "interpreter.set_tensor(input_index, input_data)\n",
    "# GET THE OUTPUT DATA\n",
    "interpreter.invoke()\n",
    "output_details = interpreter.get_output_details()\n",
    "rain_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "node_data = interpreter.get_tensor(output_details[1]['index'])\n",
    "node_data = node_data[0] # Send this to control\n",
    "prob_rain = rain_data[0]\n",
    "\n",
    "\n",
    "# Determine if it's raining\n",
    "RAIN_THRESHOLD = 0.5\n",
    "prob_rain\n",
    "node_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Model\n",
    "## On control model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Control predictions: [[0.12519471]]\n",
      "Training Model\n",
      "Epoch 1, Loss: 0.07551795989274979\n",
      "Epoch 2, Loss: 0.04582943767309189\n",
      "Epoch 3, Loss: 0.01828954741358757\n",
      "Epoch 4, Loss: 0.001427816110663116\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 17:54:54.655685: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "## Vars that need to be defined for the function \n",
    "# Recieve node_data, data_result\n",
    "BATCH_SIZE = 1 \n",
    "X_data = []  \n",
    "Y_data = []  \n",
    "data_result = 0.4\n",
    "data_result = np.array([data_result])\n",
    "\n",
    "edge_model_result = node_data\n",
    "edge_model_result = np.reshape(edge_model_result, (-1, 32)) \n",
    "\n",
    "control_predictions = control_model.predict(edge_model_result)\n",
    "print(\"Control predictions:\", control_predictions)\n",
    "\n",
    "# IF data result exists, add it and intermediate layer to batches\n",
    "if data_result.size > 0: \n",
    "    # Add data_result to Y and beginning nodes to X\n",
    "    X_data.append(edge_model_result) \n",
    "    Y_data.append(data_result) \n",
    "    if len(X_data) >= BATCH_SIZE:\n",
    "        numpy_X_data = np.vstack(X_data)\n",
    "        numpy_Y_data = np.vstack(Y_data)  \n",
    "\n",
    "        # Clear lists for the next batch\n",
    "        X_data.clear()\n",
    "        Y_data.clear()\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((numpy_X_data, numpy_Y_data))\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        # Compile and train the control_model\n",
    "        control_model.compile(optimizer='adam',\n",
    "                              loss='mean_squared_error',\n",
    "                              metrics=['mae'])\n",
    "        \n",
    "        print(\"Training Model\")\n",
    "        # Below is how models are usually trained, we need to step down from the high level api of fit() and get slightly lower down in\n",
    "        # tensorflow mush\n",
    "        # history = control_model.fit(numpy_X_data, numpy_Y_data,\n",
    "        #                             epochs=1, batch_size=BATCH_SIZE)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        for epoch in range(5):\n",
    "            with tf.GradientTape() as tape: # This will track computations performed on tensors inside the block \n",
    "                for batch_X, batch_Y in dataset:\n",
    "                    predictions = control_model(batch_X, training=True) # This is the forward pass \n",
    "                    loss = tf.keras.losses.MeanSquaredError()(batch_Y, predictions)\n",
    "                gradients = tape.gradient(loss, control_model.trainable_variables) # gradients get calculated via calling tape.gradient \n",
    "                optimizer.apply_gradients(zip(gradients, control_model.trainable_variables))\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.numpy()}\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Learning on Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_learning_model = tf.keras.models.load_model(\"../deployment/models/edge_model.keras\")\n",
    "edge_learning_model.compile(optimizer='adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mae'])\n",
    "# Extract gradients from the source model\n",
    "source_gradients = tape.gradient(loss, source_model.trainable_variables)\n",
    "\n",
    "# Step 4: Apply gradients to the target model\n",
    "# Create an optimizer for the target model\n",
    "optimizer = optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Zip gradients with target model's trainable variables\n",
    "gradient_target_pairs = zip(source_gradients, target_model.trainable_variables)\n",
    "\n",
    "# Apply gradients to the target model\n",
    "optimizer.apply_gradients(gradient_target_pairs)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
